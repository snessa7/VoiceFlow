# Shh - AI-Powered Voice Transcription for macOS

> A SuperWhisper clone built with SwiftUI, leveraging Apple's native AI capabilities and modern macOS development patterns.

## 🎯 Project Overview

**Shh** is a native macOS application that provides real-time voice-to-text transcription using Apple's foundation LLM and on-device AI capabilities. Inspired by SuperWhisper, it offers privacy-first offline transcription with a clean, SwiftUI-based interface.

### Core Features
- **Menu Bar Integration**: Persistent control in system menu bar with customizable interface
- **Offline AI Transcription**: Uses Apple's native Speech framework and on-device models
- **Real-time Processing**: Live transcription with minimal latency
- **Privacy-First**: All processing happens locally on device
- **Multi-language Support**: 100+ languages with automatic detection
- **System Integration**: Clipboard integration, keyboard shortcuts, universal app compatibility
- **SwiftUI Interface**: Modern, accessible, and responsive design

## 🏗️ Architecture

### Technology Stack
- **Frontend**: SwiftUI with shadcn-inspired component library
- **Backend**: Swift with Foundation AI integration
- **AI/ML**: Apple's Speech Framework + on-device foundation models
- **Development**: Xcode Beta 2
- **Architecture**: MVVM with Combine for reactive programming

### Key Components
1. **MenuBarExtra Scene** - Primary UI interface in system menu bar
2. **SpeechRecognizer** - Core transcription engine using Apple's Speech framework
3. **AudioManager** - Audio input/output handling and processing
4. **TranscriptionProcessor** - AI post-processing for formatting and enhancement
5. **SettingsManager** - User preferences and configuration
6. **ClipboardManager** - System clipboard integration

## 📁 Project Structure

```
Shh/
├── Documentation/           # Complete project documentation
│   ├── SwiftUI-Reference/   # SwiftUI API documentation and examples
│   ├── UI-Components/       # shadcn-inspired component library
│   └── Technical-Specs/     # Detailed technical specifications
├── Claude-Code-Instructions/ # AI agent orchestration
│   ├── master-plan.md       # Main development roadmap
│   ├── sub-agents/          # Individual task agents
│   └── progress-tracking/   # Development progress monitoring
├── Source/                  # Application source code (generated by Claude Code)
├── Resources/              # Assets, localizations, and resources
└── Tests/                  # Unit and integration tests
```

## 🚀 Development Workflow

This project uses **Claude Code** as the primary development environment with AI agent orchestration to manage complex development tasks.

### Getting Started
1. Review project documentation in `/Documentation`
2. Examine Claude Code instructions in `/Claude-Code-Instructions`
3. Execute the master plan using Claude Code's agent system
4. Monitor progress through automated tracking

### Key Development Phases
1. **Foundation Setup** - Project structure, dependencies, basic app shell
2. **Core Engine** - Speech recognition and audio processing
3. **UI Development** - SwiftUI interface with menu bar integration
4. **AI Integration** - Apple's foundation LLM integration
5. **System Integration** - Clipboard, shortcuts, accessibility
6. **Polish & Testing** - Performance optimization and comprehensive testing

## 🎨 UI/UX Design

### Design System
Built using shadcn-inspired components adapted for SwiftUI:
- **Buttons**: Multiple variants (default, destructive, outline, secondary, ghost, link)
- **Cards**: Structured content organization with headers, actions, content, footers
- **Sliders**: Volume control and sensitivity adjustments
- **Progress**: Real-time recording and processing feedback
- **Menu Components**: Rich menu bar interface with contextual actions

### Interface Patterns
- **Menu Bar First**: Primary interaction through menu bar interface
- **Window Mode**: Optional dedicated window for extended use
- **Accessibility**: Full VoiceOver support and keyboard navigation
- **Dark/Light Mode**: System appearance integration

## 🧠 AI Integration

### Apple's Foundation LLM Integration
- Leverages on-device AI models for text processing
- Speech-to-text using Apple's Speech framework
- Natural language processing for context understanding
- Offline operation with privacy preservation

### Transcription Pipeline
1. **Audio Capture** - Real-time microphone input
2. **Speech Recognition** - Apple's Speech framework
3. **Text Processing** - Foundation LLM enhancement
4. **Format Enhancement** - Punctuation, grammar, structure
5. **Output Delivery** - Clipboard, paste, or custom action

## 🛠️ Development Tools

### Primary Tools
- **Xcode Beta 2** - Latest SwiftUI and macOS features
- **Claude Code** - AI-powered development orchestration
- **Context7** - Real-time documentation and API reference
- **shadcn Components** - UI component library inspiration

### Agent-Driven Development
- **Master Agent** - Overall project coordination
- **UI Agent** - SwiftUI interface development
- **Backend Agent** - Core functionality implementation
- **Integration Agent** - System and AI integration
- **Testing Agent** - Quality assurance and testing

## 📖 Quick Start

To begin development:

```bash
# Navigate to project directory
cd /Users/sethpaonessa/Desktop/LIVE/projects/apple-dev-environment/active-projects/Shh

# Open Claude Code instructions
open Claude-Code-Instructions/master-plan.md

# Start development with Claude Code
# Follow the step-by-step agent orchestration plan
```

## 🎯 Target Features (SuperWhisper Parity)

### Core Functionality
- [x] Project setup and architecture planning
- [ ] Menu bar app with MenuBarExtra
- [ ] Real-time voice transcription
- [ ] Offline AI processing
- [ ] Multi-language support
- [ ] System clipboard integration
- [ ] Keyboard shortcuts (⌥+Space)
- [ ] Audio quality optimization

### Advanced Features
- [ ] Custom vocabulary and text replacements
- [ ] AI post-processing modes
- [ ] Meeting transcription mode
- [ ] Video transcription capability
- [ ] Export options (text, markdown, etc.)
- [ ] Usage analytics and optimization

### System Integration
- [ ] Accessibility compliance
- [ ] Sandboxing and privacy
- [ ] Performance optimization
- [ ] Battery efficiency
- [ ] Error handling and recovery

## 📝 License

This project is developed for educational and personal use, inspired by SuperWhisper's functionality while implementing original code and leveraging Apple's native AI capabilities.

---

**Next Steps**: Review `/Claude-Code-Instructions/master-plan.md` to begin the AI-orchestrated development process.
